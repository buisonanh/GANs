{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pgMC_YFScZWU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJS0lF1bsq6U",
        "outputId": "083f32c1-ea52-4f7e-8546-07119c867723"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "93FLBR-9svJl"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "y1LfNSj1s9nT",
        "outputId": "5ae455fd-b41a-4941-93f0-7952725ecf09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x222d4e13ad0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoz0lEQVR4nO3de3CV9Z3H8U+A5ACSCyHkJgHCXQTSihAQQZSUgNZCYRxFZhccR0Yb3EXa6qarILvbxuKOdemgzuyuUMeCl45AxS5ewIRWEio3EcFI0gCJJOGiSUjIjeTZPxhSI6D5Pib8kvB+zZwZc/L75Pnl4Zx8PMk53xPkeZ4nAACusC6uNwAAuDpRQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCc6OZ6A1/X2Nio48ePKzQ0VEFBQa63AwAw8jxPZ86cUXx8vLp0ufzjnHZXQMePH1dCQoLrbQAAvqPCwkL169fvsp9vdwUUGhoqSXrooYcUCARanGtoaDAfy09G+vseLbp1s5/qU6dOmTORkZHmTGVlpTkj+TsPFRUV5oyf/V177bXmjCT16tXLnDl27Jg506NHD3PGcn+4wO9t3M+ErtLSUnMmOjranOnbt68589lnn5kzktSnTx9zpqamxpzxc1/6/PPPzRnJ332jrq7OtL62tlarVq361u+rzQpo9erVevrpp1VSUqKkpCT99re/1fjx4781d+HXboFAoN0WkJ8fBMHBweZMSEiIOdO9e3dzpr6+3pzxe6za2lpzxnrjl/ztzW/Oz+3BT8bP3s6dO2fOSP4KyM/t9UqdBz97k/ztz8+5u5Lfk59j+f1zyLfl2uRJCK+++qqWLl2q5cuXa8+ePUpKSlJqaqpOnDjRFocDAHRAbVJAzzzzjB544AHdd999GjlypF544QX17NlTL774YlscDgDQAbV6AdXV1Wn37t1KSUn5+0G6dFFKSoqys7MvWl9bW6uKiopmFwBA59fqBXTq1Ck1NDQoJiam2fUxMTEqKSm5aH1GRobCw8ObLjwDDgCuDs5fiJqenq7y8vKmS2FhoestAQCugFZ/FlxUVJS6du160VMyS0tLFRsbe9F667PdAACdQ6s/AgoJCdHYsWO1devWpusaGxu1detWTZw4sbUPBwDooNrkdUBLly7VggULdOONN2r8+PF69tlnVVVVpfvuu68tDgcA6IDapIDuvvtunTx5UsuWLVNJSYm+973vacuWLRc9MQEAcPVqs0kIixcv1uLFi33nz507p65du7Z4vZ9X6kZFRZkzkpSXl2fODB8+3Jzx84pqP1MN/IySkaQJEyaYMwcPHjRn/Iyt8Tte6OzZs+ZMTk6OOTN27Fhz5ssvvzRnBg4caM5IuuRLJr7N0KFDzRk/9yU/EwA++eQTc0aSpk6das74uQ1908DOy/nb3/5mzkj+xh9Z708tnXji/FlwAICrEwUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcaLNhpN9VVFSUunfv3uL1lsGlF+Tn55szkr8hptdee6058+mnn5ozfoay3njjjeaMJA0ZMsScOXnypDnjZwhnTU2NOSNJw4YNM2f8vM+Vn4GVERER5kx5ebk5I0m33nqrOXPkyBFzxs9g0cbGRnNmzJgx5owkJSQkmDN+hvumpKSYM35uQ5JUV1dnzsTFxZnWt/T+xyMgAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAONFup2HX1NTI87wWr+/Wzf6t1NbWmjOSv2m827dvN2fKysrMmfnz55szr732mjkj+Tt//fv3N2f8/NueOnXKnJGkt99+25zxM4n93Llz5kzfvn3NmYEDB5ozkvTWW2+ZM5MmTTJnPvzwQ3Nm+vTp5swnn3xizkhX7udKZWWlOePn54Pk73vKy8szrW/pxG0eAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAE+12GGlVVZVpYGPv3r3Nx+jevbs5I0nJycnmjHWYnyT16NHDnHn55ZfNmZEjR5ozknT8+HFzZtiwYebMmjVrzJlf/epX5owk/fWvfzVntm7das4UFBSYM9ddd505s3v3bnNGkh5++GFz5s9//rM5M2vWLHPmiy++MGfCw8PNGUkqKioyZ/x8T5s2bTJn/A5TDgoKMmduueUW0/rq6mr97ne/+9Z1PAICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACfa7TDS+vp6denS8n4MDg42H2PChAnmjCTt3bvXnImNjTVnGhoazJmePXuaM0eOHDFnJGny5MnmzPLly82ZW2+91Zzxc+4kafDgwebMv/7rv5ozzz77rDnT2NhozkRGRpozkvT444+bMwsWLDBn/AxLveGGG8wZP+dOknr16mXO7Nmzx5xJSkoyZ/7v//7PnJGkqVOnmjOlpaWm9TU1NS1axyMgAIATFBAAwIlWL6Ann3xSQUFBzS4jRoxo7cMAADq4Nvkb0PXXX6/33nvv7wfp1m7/1AQAcKRNmqFbt26+/ugOALh6tMnfgA4fPqz4+HgNGjRI8+fP17Fjxy67tra2VhUVFc0uAIDOr9ULKDk5WWvXrtWWLVv0/PPPq6CgQJMnT9aZM2cuuT4jI0Ph4eFNl4SEhNbeEgCgHWr1Apo5c6buuusujRkzRqmpqfrTn/6ksrIyvfbaa5dcn56ervLy8qZLYWFha28JANAOtfmzAyIiIjRs2DDl5eVd8vOBQECBQKCttwEAaGfa/HVAlZWVys/PV1xcXFsfCgDQgbR6Af3sZz9TVlaWjhw5oh07dujHP/6xunbtqnnz5rX2oQAAHVir/wquqKhI8+bN0+nTp9W3b1/dfPPNysnJUd++fVv7UACADqzVC+iVV15pla/Tu3dvde/evcXrKysrzceora01ZyQpKCjInImOjjZncnNzzZmRI0eaMwcPHjRnJGns2LHmTEREhDlTV1dnzrz88svmjCQNGDDAnPmv//ovc+ZPf/qTOVNcXGzO3HfffeaMJD3zzDPmzK9//Wtzxs/twc8L2/0MMJWkzz77zJyx/Ny6ICoqypxJTEw0Z/yyvjympT9bmQUHAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE60+RvS+eV5nhobG1u83s9Qw6NHj5ozktTQ0GDOfPzxx1fkOKNHjzZnduzYYc5I0pNPPmnOjBo1ypwZPny4OVNdXW3OSP4GwBYUFJgzw4YNM2dmzZplzrz11lvmjCQ999xz5szcuXPNmSNHjpgzfpw+fdpXzs/g4XPnzpkzJ06cMGc++eQTc0byN5jV+rOyvr6+Ret4BAQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAn2u007JMnTyokJKTF67t27Wo+Rq9evcwZyd9E55KSEnPGzzTsjRs3mjOxsbHmjCR9+eWX5kxhYaE543meORMWFmbOSNLnn39uzkydOtWcCQ4ONme6dbPfXf1MEpekn/zkJ+bMSy+9ZM786Ec/Mmc++OADc6Znz57mjCRVVVWZMwkJCeaMn+ntQ4cONWck6cMPPzRnJk2aZFpfXV2tP/zhD9+6jkdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEux1G2q1bN9Pwxeuvv958jC+++MKckaQ1a9aYM4899pg5k52dbc7cfffd5oyfoaKSfUChJD333HPmzLXXXmvOvPvuu+aMJE2bNs2cufHGG82ZX/7yl+bM4MGDzZnw8HBzRpI2bNhwRY517733mjMff/yxObNy5UpzRpLGjRtnzhw+fNic8TNYtLS01JyRpLi4OHOmoqLCtL6mpqZF63gEBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOBHme57nexFdVVFQoPDxcK1asUPfu3VucKykpMR/r5MmT5ozkb0BhQ0ODOfPhhx+aM2VlZebMvHnzzBlJ2rx5szkzd+5cc+aDDz4wZ/z8G0nSwYMHzRk/wyf9DISMjo42Zyz3oa+yDAK+oLi42JxJSEgwZ3r06GHOFBUVmTOSv4GfjY2N5kzPnj3Nmdtuu82ckaScnBxz5vTp06b1dXV1evHFF1VeXq6wsLDLruMREADACQoIAOCEuYC2b9+uO++8U/Hx8QoKCtLGjRubfd7zPC1btkxxcXHq0aOHUlJSfP2KAgDQuZkLqKqqSklJSVq9evUlP79y5UqtWrVKL7zwgnbu3KlrrrlGqampLX6DIgDA1cH8l8aZM2dq5syZl/yc53l69tln9fjjj2vWrFmSpJdeekkxMTHauHGj7rnnnu+2WwBAp9GqfwMqKChQSUmJUlJSmq4LDw9XcnLyZd9eura2VhUVFc0uAIDOr1UL6MJToWNiYppdHxMTc9mnSWdkZCg8PLzp4udpmQCAjsf5s+DS09NVXl7edCksLHS9JQDAFdCqBRQbGyvp4hdvlZaWNn3u6wKBgMLCwppdAACdX6sWUGJiomJjY7V169am6yoqKrRz505NnDixNQ8FAOjgzM+Cq6ysVF5eXtPHBQUF2rdvnyIjI9W/f38tWbJE//Ef/6GhQ4cqMTFRTzzxhOLj4zV79uzW3DcAoIMzF9CuXbt06623Nn28dOlSSdKCBQu0du1aPfroo6qqqtKiRYtUVlamm2++WVu2bPE9kwoA0Dm122GkTz31lKm0/AzhvOaaa8wZyd9QyP3795szISEh5oyfJ3EMGzbMnJH8DVA8deqUOeNnIKTf76lXr17mzMcff2zOzJ8/35xJS0szZ37+85+bM9L51+9ZjR8/3pz54osvzJn+/fubM35f3vHiiy+aM5d7kf438TNw18+wYun8S2OskpOTTetramr01FNPMYwUANA+UUAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4IT57RiulEOHDpmmQdfX15uPcebMGXNGkm6//XZzxs/kbT9Tlv1MCg4KCjJnJOns2bPmzB133GHO/Od//qc5c/DgQXNGkkaNGuUrZ/Xmm2+aM4MGDTJnNm/ebM5I0ieffGLOREZGmjN+3gF5/fr15sx1111nzkhSnz59zJnJkyebM8XFxeZMIBAwZyTp5MmT5kxERIRpfU1NTYvW8QgIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJxot8NIQ0NDTcP2hg4daj5GSUmJOSNJ7733njkzevRoc8bPQM0pU6aYM5s2bTJnJOkHP/jBFTmWn0GSY8aMMWckfwNq3377bXMmLS3NnPEzwPRf/uVfzBlJ+uijj8yZm266yZyprq42ZyZMmGDO+Dl3krRgwQJzZsWKFeZMcnKyOZOXl2fOSP7uT+Xl5ab1DCMFALRrFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCi3Q4jra6uVkNDQ4vXf/rpp+ZjWL7+V82bN8+cOX78uDkzdepUcyYmJsacmTFjhjnjV0pKijlTWFhozhQXF5szkvT973/fnLn//vvNmQMHDpgzI0eONGf8fD+SNGfOHHPGz8DdHTt2mDPdu3c3Z5566ilzRpI2b95szsTHx5szZWVl5sxdd91lzkjSiy++aM7cfvvtpvVnz55t0ToeAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAE+12GGlsbKxp6KCfoYZJSUnmjCR99NFH5kxoaKg5c/PNN5szfoae+h3K+uWXX5ozfv6dEhMTzZlTp06ZM5K/oZDZ2dnmTM+ePc2ZG264wZzJzc01ZySpb9++5sz27dvNmeHDh5szmZmZ5syuXbvMGcnf4NMf/vCH5swf/vAHc+add94xZyRpwoQJ5oz1Z15tbW2L1vEICADgBAUEAHDCXEDbt2/XnXfeqfj4eAUFBWnjxo3NPr9w4UIFBQU1u1zJ95sBAHQM5gKqqqpSUlKSVq9efdk1M2bMUHFxcdNl/fr132mTAIDOx/wkhJkzZ2rmzJnfuCYQCCg2Ntb3pgAAnV+b/A0oMzNT0dHRGj58uB566CGdPn36smtra2tVUVHR7AIA6PxavYBmzJihl156SVu3btWvf/1rZWVlaebMmZd9qm9GRobCw8ObLgkJCa29JQBAO9TqrwO65557mv579OjRGjNmjAYPHqzMzExNmzbtovXp6elaunRp08cVFRWUEABcBdr8adiDBg1SVFSU8vLyLvn5QCCgsLCwZhcAQOfX5gVUVFSk06dPKy4urq0PBQDoQMy/gqusrGz2aKagoED79u1TZGSkIiMjtWLFCs2dO1exsbHKz8/Xo48+qiFDhig1NbVVNw4A6NjMBbRr1y7deuutTR9f+PvNggUL9Pzzz2v//v363e9+p7KyMsXHx2v69On693//dwUCgdbbNQCgwzMX0NSpU+V53mU///bbb3+nDV1QVFSkkJCQFq8fOnSo+RjBwcHmjORvkGRJSYk588EHH5gzo0aNMmfi4+PNGcnf9+Rn+OQvfvELc2bWrFnmjCR9/vnn5kxNTY0542fI5T/8wz+YM4888og5I0kpKSnmzIEDB8yZjz/+2JyJiIgwZ0aOHGnOSNKRI0fMGT/nwc/3NG/ePHNG8vdzZdCgQab1Lb1PMAsOAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATrT6W3K3lp49e5rewqFfv37mYyQmJpozkvT++++bMz/60Y/MmT/+8Y/mjJ+pun4m/krSD3/4Q3Nm48aN5syyZcvMGb/vrPvOO++YM9nZ2ebMP/3TP5kzmZmZ5szy5cvNGUlauHChOTNx4kRz5qtv7dJSb7zxhjmTlJRkzkhSnz59zJktW7aYM35+Pvj9nl5++WVz5vvf/75pfUvfyYBHQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgRLsdRmp19OhRc6aoqMjXsXr37m3ObNu2zZyZPHmyOVNWVmbO9OjRw5yR/J2/+Ph4c8bPsM+BAweaM5L0j//4j+ZMQ0ODOdPSYY1f9cILL5gzDz74oDkjSevXrzdnVq5cac7s2LHDnLntttvMmTNnzpgzknTw4EFzxs9t/MMPPzRnzp49a85I0pgxY8wZ68+VmpqaFq3jERAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAONFuh5FGRkaqe/fuLV6fk5NjPsaoUaPMGUlqbGw0Z4YOHWrOPP300+bM9OnTzRm/Vq1aZc5MmTLFnPEzWHTIkCHmjN/cnDlzzBk/Qzj9DEr1cxxJ8jzPnAkLC/N1LKu3337bnPFz/5Ok4uJic+amm24yZ6KioswZv3r27GnObN++3bS+rq6uRet4BAQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATrTbYaRWffr0MWeCg4N9HauhocGc2bt3rzlz5513mjN+hieeO3fOnJGklJQUc+aOO+4wZ15//XVzJjEx0ZyRpJdeesmcGTdunDlTVFRkzixbtsycOXr0qDkjSV262P/f9KOPPjJn/NxvR4wYYc6cOXPGnJGkHj16mDN79uwxZ/wMcj1w4IA5I0mTJ082Z3r37m1aX1tb26J1PAICADhBAQEAnDAVUEZGhsaNG6fQ0FBFR0dr9uzZys3NbbampqZGaWlp6tOnj3r16qW5c+eqtLS0VTcNAOj4TAWUlZWltLQ05eTk6N1331V9fb2mT5+uqqqqpjWPPPKI3nzzTb3++uvKysrS8ePHfb1hFwCgczM9CWHLli3NPl67dq2io6O1e/duTZkyReXl5frf//1frVu3Trfddpskac2aNbruuuuUk5OjCRMmtN7OAQAd2nf6G1B5ebmk82+fLUm7d+9WfX19s2dHjRgxQv3791d2dvYlv0Ztba0qKiqaXQAAnZ/vAmpsbNSSJUs0adIkjRo1SpJUUlKikJAQRURENFsbExOjkpKSS36djIwMhYeHN10SEhL8bgkA0IH4LqC0tDQdOHBAr7zyynfaQHp6usrLy5suhYWF3+nrAQA6Bl8vRF28eLE2b96s7du3q1+/fk3Xx8bGqq6uTmVlZc0eBZWWlio2NvaSXysQCCgQCPjZBgCgAzM9AvI8T4sXL9aGDRu0bdu2i15tPnbsWAUHB2vr1q1N1+Xm5urYsWOaOHFi6+wYANApmB4BpaWlad26ddq0aZNCQ0Ob/q4THh6uHj16KDw8XPfff7+WLl2qyMhIhYWF6eGHH9bEiRN5BhwAoBlTAT3//POSpKlTpza7fs2aNVq4cKEk6Te/+Y26dOmiuXPnqra2VqmpqXruuedaZbMAgM4jyPM8z/UmvqqiokLh4eF69NFHTX8b6tq1q/lYfgYASrpo+kNL+PkVpJ/9+RkIaR00eMGhQ4fMmfnz55szfgZqVlZWmjOSdMMNN5gzfgaLlpWVmTNRUVHmjJ+hopK0bds2c2bGjBnmzFtvvWXOxMXFmTPvvPOOOSNJU6ZMMWeu1EtJ/Aw4lnTRs5RbYu7cuab11dXVWrRokcrLy7/x5xiz4AAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOCEr3dEvRKCg4MVEhLS4vXHjx83H6O8vNyckaT4+Hhzxs9bjX/22WfmzKRJk8yZxsZGc0aSIiMjzZkvv/zSnMnKyjJn/PwbSdL27dvNmYaGBnMmPz/fnOnVq5c542dKvCRFR0ebMzt27DBnqqqqzJmgoCBzxs90b0lKT083ZwYOHGjO1NXVmTNJSUnmjCR9+umn5szBgwdN62tra1u0jkdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEux1GWlRUZBpG6mdAoZ8hkpK/YYP9+vUzZ0pLS80Zz/PMmRtvvNGckaQjR46YM9nZ2ebMn//8Z3Nm8eLF5ozkb6jtvn37zBk/5/zw4cPmTGpqqjkj+RtY2aWL/f9nT58+bc74ud/+93//tzkjSTt37jRn7rjjDnPm2LFj5sypU6fMGb9iYmJM62tqalq0jkdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEux1GGhYWpkAg0OL1Y8eONR/j888/N2ckf4MaP/vsM3OmqqrKnKmtrTVncnNzzRlJqqioMGfCw8PNmZtuusmc8TPkUvI3FPKWW24xZ7p1s9/1lixZYs68+uqr5owkXX/99ebM3r17zZmf/vSn5swzzzxjzhQUFJgzkr8hwpWVlebMkCFDzBnLz8ev+uKLL8yZrl27mta3dDAtj4AAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwIl2O4y0trZWnue1eP3JkyfNx/CTkaTk5GRzprq62pxZtWqVOZOYmGjOnDlzxpyRpEmTJpkzfgafzp4925zZuHGjOSNJc+bMMWfWrVtnznzve98zZx588EFz5le/+pU5I0n79+83Z+rr682ZQ4cOmTMZGRnmzJtvvmnO+JWQkGDOWH7WXbBr1y5zRpKCg4PNmbvuusu0vqWDlHkEBABwggICADhhKqCMjAyNGzdOoaGhio6O1uzZsy/6lcrUqVMVFBTU7OLnVwcAgM7NVEBZWVlKS0tTTk6O3n33XdXX12v69OkX/b7vgQceUHFxcdNl5cqVrbppAEDHZ3oSwpYtW5p9vHbtWkVHR2v37t2aMmVK0/U9e/ZUbGxs6+wQANApfae/AZWXl0uSIiMjm13/+9//XlFRURo1apTS09N19uzZy36N2tpaVVRUNLsAADo/30/Dbmxs1JIlSzRp0iSNGjWq6fp7771XAwYMUHx8vPbv36/HHntMubm5euONNy75dTIyMrRixQq/2wAAdFC+CygtLU0HDhzQX/7yl2bXL1q0qOm/R48erbi4OE2bNk35+fkaPHjwRV8nPT1dS5cubfq4oqLC1/PoAQAdi68CWrx4sTZv3qzt27erX79+37j2wos28/LyLllAgUBAgUDAzzYAAB2YqYA8z9PDDz+sDRs2KDMzs0Wvut+3b58kKS4uztcGAQCdk6mA0tLStG7dOm3atEmhoaEqKSmRJIWHh6tHjx7Kz8/XunXrdPvtt6tPnz7av3+/HnnkEU2ZMkVjxoxpk28AANAxmQro+eefl3T+xaZftWbNGi1cuFAhISF677339Oyzz6qqqkoJCQmaO3euHn/88VbbMACgczD/Cu6bJCQkKCsr6zttCABwdWi307Cttm3bZs6MGDHC17EqKyvNmVOnTpkzX31xb0vV1dWZM7NmzTJnJOmJJ54wZwYOHGjOZGdnmzN+J3z/z//8jzkzcuRIc8bP9OMf/OAH5szhw4fNGUnq0sX+EsETJ06YM6dPnzZn/Pwb+blfSP4mRx89etScGTJkiDkTHx9vzkhSQUGBOWN9YFFTU9OidQwjBQA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAn2u0w0t69e5veKTUiIsJ8jAvvZ2TlZwjg3r17zZl77rnHnPnb3/5mzvgZIilJqamp5swf//hHc6Zv377mjJ/BnZL0m9/8xpzxcx5efvllc2b58uXmzHPPPWfOSNKjjz5qzuzZs8ec6d+/vzlTUVFhzlx33XXmjCTl5uaaM3fccYc5s3btWnPGzxBcSTp06JA5ExkZaVpfXV3donU8AgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE60u1lwnudJkmpra025xsZG87Hq6urMGUmqqqoyZ6zfj9TyeUpfVVNTY86cPXvWnPF7rHPnzpkz9fX15oyfcydJDQ0N5oyf8+DnOH7+nfycO8nfbdzPsfx8T1fqvuT3WJWVleaMn59Ffr+nK3F/unCfuPDz/HKCvG9bcYUVFRUpISHB9TYAAN9RYWGh+vXrd9nPt7sCamxs1PHjxxUaGqqgoKBmn6uoqFBCQoIKCwsVFhbmaIfucR7O4zycx3k4j/NwXns4D57n6cyZM4qPj1eXLpf/S0+7+xVcly5dvrExJSksLOyqvoFdwHk4j/NwHufhPM7Dea7PQ3h4+Leu4UkIAAAnKCAAgBMdqoACgYCWL19ueqfUzojzcB7n4TzOw3mch/M60nlod09CAABcHTrUIyAAQOdBAQEAnKCAAABOUEAAACc6TAGtXr1aAwcOVPfu3ZWcnKy//vWvrrd0xT355JMKCgpqdhkxYoTrbbW57du3684771R8fLyCgoK0cePGZp/3PE/Lli1TXFycevTooZSUFB0+fNjNZtvQt52HhQsXXnT7mDFjhpvNtpGMjAyNGzdOoaGhio6O1uzZs5Wbm9tsTU1NjdLS0tSnTx/16tVLc+fOVWlpqaMdt42WnIepU6dedHt48MEHHe340jpEAb366qtaunSpli9frj179igpKUmpqak6ceKE661dcddff72Ki4ubLn/5y19cb6nNVVVVKSkpSatXr77k51euXKlVq1bphRde0M6dO3XNNdcoNTXV15DQ9uzbzoMkzZgxo9ntY/369Vdwh20vKytLaWlpysnJ0bvvvqv6+npNnz692fDURx55RG+++aZef/11ZWVl6fjx45ozZ47DXbe+lpwHSXrggQea3R5WrlzpaMeX4XUA48eP99LS0po+bmho8OLj472MjAyHu7ryli9f7iUlJbnehlOSvA0bNjR93NjY6MXGxnpPP/1003VlZWVeIBDw1q9f72CHV8bXz4Pned6CBQu8WbNmOdmPKydOnPAkeVlZWZ7nnf+3Dw4O9l5//fWmNYcOHfIkednZ2a622ea+fh48z/NuueUW75//+Z/dbaoF2v0joLq6Ou3evVspKSlN13Xp0kUpKSnKzs52uDM3Dh8+rPj4eA0aNEjz58/XsWPHXG/JqYKCApWUlDS7fYSHhys5OfmqvH1kZmYqOjpaw4cP10MPPaTTp0+73lKbKi8vlyRFRkZKknbv3q36+vpmt4cRI0aof//+nfr28PXzcMHvf/97RUVFadSoUUpPT/f91ittpd0NI/26U6dOqaGhQTExMc2uj4mJ0aeffupoV24kJydr7dq1Gj58uIqLi7VixQpNnjxZBw4cUGhoqOvtOVFSUiJJl7x9XPjc1WLGjBmaM2eOEhMTlZ+fr1/84heaOXOmsrOz1bVrV9fba3WNjY1asmSJJk2apFGjRkk6f3sICQlRREREs7Wd+fZwqfMgSffee68GDBig+Ph47d+/X4899phyc3P1xhtvONxtc+2+gPB3M2fObPrvMWPGKDk5WQMGDNBrr72m+++/3+HO0B7cc889Tf89evRojRkzRoMHD1ZmZqamTZvmcGdtIy0tTQcOHLgq/g76TS53HhYtWtT036NHj1ZcXJymTZum/Px8DR48+Epv85La/a/goqKi1LVr14uexVJaWqrY2FhHu2ofIiIiNGzYMOXl5bneijMXbgPcPi42aNAgRUVFdcrbx+LFi7V582a9//77zd6+JTY2VnV1dSorK2u2vrPeHi53Hi4lOTlZktrV7aHdF1BISIjGjh2rrVu3Nl3X2NiorVu3auLEiQ535l5lZaXy8/MVFxfneivOJCYmKjY2ttnto6KiQjt37rzqbx9FRUU6ffp0p7p9eJ6nxYsXa8OGDdq2bZsSExObfX7s2LEKDg5udnvIzc3VsWPHOtXt4dvOw6Xs27dPktrX7cH1syBa4pVXXvECgYC3du1a7+DBg96iRYu8iIgIr6SkxPXWrqif/vSnXmZmpldQUOB98MEHXkpKihcVFeWdOHHC9dba1JkzZ7y9e/d6e/fu9SR5zzzzjLd3717v6NGjnud53lNPPeVFRER4mzZt8vbv3+/NmjXLS0xM9Kqrqx3vvHV903k4c+aM97Of/czLzs72CgoKvPfee8+74YYbvKFDh3o1NTWut95qHnroIS88PNzLzMz0iouLmy5nz55tWvPggw96/fv397Zt2+bt2rXLmzhxojdx4kSHu25933Ye8vLyvH/7t3/zdu3a5RUUFHibNm3yBg0a5E2ZMsXxzpvrEAXkeZ7329/+1uvfv78XEhLijR8/3svJyXG9pSvu7rvv9uLi4ryQkBDv2muv9e6++24vLy/P9bba3Pvvv+9JuuiyYMECz/POPxX7iSee8GJiYrxAIOBNmzbNy83NdbvpNvBN5+Hs2bPe9OnTvb59+3rBwcHegAEDvAceeKDT/U/apb5/Sd6aNWua1lRXV3s/+clPvN69e3s9e/b0fvzjH3vFxcXuNt0Gvu08HDt2zJsyZYoXGRnpBQIBb8iQId7Pf/5zr7y83O3Gv4a3YwAAONHu/wYEAOicKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAODE/wOBEyEn4CJKOwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IUUYbgKts_3M"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GUx8FKoxeOb",
        "outputId": "93a68258-ca2a-4972-eb58-8808bb82afb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.00116852]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-zhGzK2dw8Ey"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qJWUL4w8w-Se"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1RVK7GTrxKeb"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sxGWgUuT0ClM"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5BQcVeFo2DMP"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 200\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zXf0Dr8v2Dyb"
      },
      "outputs": [],
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2Kpn_yWg2FHr"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5k_24b3Y2GTL"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jPCjrR252HyS",
        "outputId": "661e177c-f3b7-4c4a-cfa9-cbea200c76bf"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[16], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m----> 6\u001b[0m   \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Produce images for the GIF as you go\u001b[39;00m\n\u001b[0;32m      9\u001b[0m display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBHwG9zL2JXz"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wuB-hdX2NdN"
      },
      "outputs": [],
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3FhyuCm2PBC"
      },
      "outputs": [],
      "source": [
        "display_image(EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-RrUAG1jSUg"
      },
      "outputs": [],
      "source": [
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vA4_HD52TNu"
      },
      "outputs": [],
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa5AsTUG2Uzr"
      },
      "outputs": [],
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
